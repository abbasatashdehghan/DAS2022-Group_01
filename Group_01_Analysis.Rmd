---
title: "Group_01_Analysis.Rmd"
author: "Group_01"
date: "3/14/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, message=TRUE, warning=FALSE,error=TRUE, echo=TRUE}
library(tidyverse)
library(moderndive)
library(skimr)
library(readr)
library(Stat2Data)
library(ggplot2)
library(GGally)
library(broom)
library(sjPlot)
library(DescTools)
library(knitr)
library(gridExtra)
library(janitor)
library(dplyr)
```
# Introduction {#sec:Intro}

Dataset comes from the FIES (Family Income and Expenditure Survey) recorded in the Philippines. The survey, which is undertaken every three years, is aimed at providing data on family income and expenditure. In this study, we are going to identify the most influential variables on the number of people living in a household using a Generalised Linear Model. Below you can see an overview of the data and variables
```{r, message=FALSE, warning=F}
data <- read.csv("dataset1.csv", stringsAsFactors = T) %>% 
  rename("Number_of_Family"=7,"Income" = 1, "Expenditure" = 3,
         "Gender" = 4, "Age" = 5,"Type" = 6, "Area" = 8,"HouseAge" = 9,
         "Bedrooms" = 10) %>% select(-2)


data <- data %>% filter(Type != "Two or More Nonrelated Persons/Members") %>% 
  mutate(Type = factor(Type, levels = c("Single Family", "Extended Family")))
 
#Region column removed from the data
  
glimpse(data)
```

$FoodExpenditure$ is the annual expenditure by the household on food (in Philippine peso)  
$Gender$ is the head of the households sex  
$Age$ is the head of the households age (in years)  
$Type$ is the relationship between the group of people living in the house  
$Number_of_Family$ is the number of people living in the house  
$Area$ is the floor area of the house (in $m^2$)  
$HouseAge$ is the age of the building (in years)  
$bedrooms$ is the number of bedrooms in the house  
$Electricity$ indicates that if the house have electricity? (1=Yes, 0=No)  

# Exploratory Data Analysis {#sec:EDA}
The following tables and graphs are produced to provide statistical summaries and graphs to see the distribution variables and their relationship and identify any possible outliers.

```{r data_summary}
# summary(data)
data[,-c(3,5,11)] %>% skim() %>% 
  select(skim_variable,numeric.p0,
                       numeric.mean, numeric.sd, numeric.p50, numeric.p100) %>% 
  kable(caption = "\\label{tabel:summary} Summary Statistics", 
        col.names = c("Variable", "Min", "Mean",
                                       "SD", "Median", "Max"),
        align = rep("c", 6), digits = 1)
```

Referring to \ref{tabel:summary}, the difference between mean and median indicates the presence of outliers in the data. The following pair plots fuhrer support the presence of outliers. 


```{r pairplot1, fig.cap="\\label{fig:pairplot1} The pair plot (first five variables) shows the relationship between each of the two variables", message=FALSE, warning=FALSE}
data[,c(1:6)] %>% ggpairs()

```

```{r pairplot2, fig.cap="\\label{fig:pairplot2} The pair plot (second five variables) shows the relationship between each of the two variables", message=FALSE, warning=FALSE}
data[,c(7:10, 6)] %>% ggpairs()

```

Figure \ref{fig:outliers} presents the distribution of outcome variables with regards to each of the continuous variables. The boxplots can help us identify the outliers 

```{r outliers, fig.cap="\\label{fig:outliers} The boxplot of the outcome variables vs each of the continuous explanatory variables", message=FALSE, warning=FALSE}
# Defining a fucntion to draw multiple boxplots for the outcome variables
graph_function <- function(x){
  ggplot(data = data, aes(x = "", y = get(x))) + 
    geom_boxplot(color = "steelblue") + 
    theme(legend.position = "none") + labs(y = x, x = "Number_of_Family_members") + 
    scale_y_continuous(limits = c(min(data[[x]])*0.9, max(data[[x]])*1.1)) + 
    stat_summary(fun.y = mean, geom = "errorbar", aes(ymax = ..y.., ymin = ..y..),
                 width = .75, linetype = "dashed") + 
    theme_classic() 
}  
#Boxplots of outcome variable vs other continous variables:
graphs <- lapply(names(data)[c(1,2,4,7,8,9)], graph_function)

grid.arrange(graphs[[1]],graphs[[2]],graphs[[3]],graphs[[4]],
                  graphs[[5]],graphs[[6]], ncol = 2)

```

Once the outliers are spotted and removed, the skewness in data is decreased. The Figure \ref{fig:outliersremoved} displays the box plots after removing outliers and log transforming Income, Expenditure and Area.

```{r outliersremoved, fig.cap="\\label{fig:outliersremoved} The boxplot of the outcome variables vs each of the continuous explanatory variables after removing outliers and applying log transformation", message=FALSE, warning=FALSE}

#Removing outliers 
data <- data %>% filter(Income < 830000 & Area < 500 & HouseAge > 0)

data <- data %>% mutate(across(c(1,2,7,8), log)) %>% rename("Log.Income" = "Income",
                                                 "Log.Expenditure" = "Expenditure",
                                                 "Log.Area" = "Area",
                                                 "Log.HouseAge" = "HouseAge")

graphs_updated <- lapply(names(data)[c(1,2,4,7,8,9)], graph_function)

p <- grid.arrange(graphs_updated[[1]],graphs_updated[[2]],graphs_updated[[3]],
                  graphs_updated[[4]],graphs_updated[[5]],graphs_updated[[6]],
                  ncol = 2)

p
```


The table \ref{tabel:summary_outlier_removed} shows the summary statistics after removing outliers and transforming the variables of Income, Expenditure and Aare using log transformation. The difference between medians and means are now narrower. 

```{r data_summary_outliers_removed}
data[,-c(3,5,11)] %>% skim() %>% 
  select(skim_variable,numeric.p0,
                       numeric.mean, numeric.sd, numeric.p50, numeric.p100) %>% 
  kable(caption = "\\label{tabel:summary_outlier_removed} Summary Statistics after outliers removed", 
        col.names = c("Variable", "Min", "Mean",
                                       "SD", "Median", "Max"),
        align = rep("c", 6), digits = 1)
```



The Figure \ref{fig:hist} and \ref{fig:hist} shows the distribution of household sizes and simulated Poisson distribution with the mean value of `r round(mean(data$Number_of_Family),1)` respectively.

```{r hist, fig.cap="\\label{fig:hist} Distribtion of the size of families", message=FALSE, warning=FALSE}
plotdata = data %>% count(Number_of_Family) %>% 
  mutate(pct = n / sum(n),
         pctlabel = paste0(round(pct*100,1), "%"))
plotdata %>% ggplot(aes(x = as.factor(Number_of_Family), y = n)) + 
  geom_col(stat = "identity", 
           fill = "indianred3", 
           color = "black")  +
   geom_text(aes(label = pctlabel), 
            vjust = -0.25) + 
  labs(x = "Number_of_Family", 
       y = "Frequency", 
       title  = "Histogram of the number of familiy members") + 
  theme_classic() 


```
```{r Simulate, fig.cap="\\label{fig:hist} Simulate Poisson with the same lambda as our data", message=FALSE, warning=FALSE}
#Simulate Poisson with the same lambda as our data
set.seed(1)
data.frame(data = rpois(500, lambda=mean(data$Number_of_Family))) %>% 
  count(data) %>% 
  ggplot(aes(x = as.factor(data), y = n)) + 
  geom_col(fill ="#2166AC") + 
  labs(x = "x", 
       title =paste("Simulated Poisson distribution with the mean of", 
                    round(mean(data$Number_of_Family),1))) + 
  theme_classic()
```


The histogram (Figure \ref{fig:hist} ) of the family size resembles a Poisson distribution.

# Formal Data Analysis
In this section we model the data to identify the most influential factors on the number of family members using Poisson distribution since the the outcome variabl is a count data. Then the goodness of fit comparison is made to select the best model based on AIC and Deviance. However, for the a Poisson to completly hold the variance and mean shall be equal. The variance and the mean are `r round(data$Number_of_Family %>% var(),1)` and `r round(data$Number_of_Family %>% mean(),1)`. We can say that they are roughly equal.

## Poisson  model
```{r poisson, echo=TRUE}
model.poisson = glm(data = data, Number_of_Family ~ Log.Income + Log.Expenditure + 
                       Gender + Age + Type + Log.Area + Log.HouseAge + Bedrooms + Electricity,
                     family = poisson(link = "log"))
initial.poisson.AIC = model.poisson$aic
summary(model.poisson)
```

We now try to see if we can improve model AIC and decrease the deviance using step function. In this method we start from the full model and every time drop one variable and calculate the AIC. This procedure is continued until no further reduction in AIC is observed.
```{r PoissonAIC}
step(model.poisson)

# model with loghouse included
model.poisson = glm(data = data, Number_of_Family ~ Log.Income + Log.Expenditure + 
                       Gender + Type + Bedrooms + Log.HouseAge,
                     family = poisson(link = "log"))
second.poisson.AIC = model.poisson$aic

summary(model.poisson)

```

By removing Electricity and Area and Age, the AIC is reduced from `r round((initial.poisson.AIC),1)` to `r round((second.poisson.AIC),1)`. We now check for the goodness of fit by comparing it against the null model. The 95 percent $\chi^2$(p = 0.95, df = `r model.poisson$df.null - model.poisson$df.residual`) equals `r round(qchisq(df=model.poisson$df.null - model.poisson$df.residual, p=0.95), 1)`. Taking the difference in deviances (likelihood ratio test) results in the value of `r round((model.poisson$null.deviance - model.poisson$deviance),1)` which is significant when compared to `r round(qchisq(df=model.poisson$df.null - model.poisson$df.residual, p=0.95), 1)`. Therefore, there is no deviance of lack of fit with our model after removing the variables. The Log.HouseAge is not also significantly different from zero and by removing it, the AIC remains almost constant(`r round(model.poisson$aic,1)`), however, the BIC is further reduced by 5 after removing Log.HouseAge. The Pseudo_R2 remains almost the same for all models. Table \ref{tabel:modelcomparison} presents AIC, BIC and Pseudo-R2 for the models assessed in our analysis. They are shown in order of dropping variables from the full model. For example "Fâ€”Age" represents the model with Electricity, Log.Area and Area removed.
Given above, The formula below is proposed to model expected count:
$$log(Number\_ of\_Family) =\beta_0 + \beta_1 \cdot log(Income) + \beta_2 \cdot log(FoodExpenditure) + \beta_3 \cdot Gender + \beta_4 \cdot Bedrooms+ 
\beta_5 \cdot Type$$


```{r modelcomparison}

Models = c("Fullmodel", "F-Electricity", "F--Log.Area", "F---Age", 
           "F----Log.House")

Fullmodel = glm(data = data, Number_of_Family ~ Log.Income + Log.Expenditure + 
                      Gender + Age + Type + Log.Area + Log.HouseAge + Bedrooms + Electricity,
                    family = poisson(link = "log"))
Fullmodel.params <- round(glance(Fullmodel),1)

F_Electricity = glm(data = data, Number_of_Family ~ Log.Income + Log.Expenditure + 
                  Gender + Age + Type + Log.Area + Log.HouseAge + Bedrooms,
                family = poisson(link = "log"))
F_Electricity.params <- round(glance(F_Electricity),1)


F_Log.Area = glm(data = data, Number_of_Family ~ Log.Income + Log.Expenditure + 
                      Gender + Age + Type + Log.HouseAge + Bedrooms,
                    family = poisson(link = "log"))
F_Log.Area.params <- round(glance(F_Log.Area),1)


F_Age = glm(data = data, Number_of_Family ~ Log.Income + Log.Expenditure + 
                   Gender  + Type + Log.HouseAge + Bedrooms,
                 family = poisson(link = "log"))
F_Age.params <- round(glance(F_Age),1)


F_Log.House = glm(data = data, Number_of_Family ~ Log.Income + Log.Expenditure + 
              Gender  + Type + Bedrooms,
            family = poisson(link = "log"))
F_Log.House.params <- round(glance(F_Log.House),1)



McFadden <- data.frame(pseudo_R2 = c(PseudoR2(Fullmodel),
                                     PseudoR2(F_Electricity),
                                     PseudoR2(F_Log.Area),
                                     PseudoR2(F_Age),
                                     PseudoR2(F_Log.House)))

bind_rows(Fullmodel.params,
          F_Electricity.params,F_Log.Area.params,F_Age.params,F_Log.House.params,
          .id = "Model") %>% 
  select(Model, AIC, BIC) %>% 
  mutate(Model = Models) %>% cbind(McFadden) %>%
  kable(
    digits = 3,
    caption = "\\label{tabel:modelcomparison}Model comparison values for different models.")


```
      
## Parameter estimates
Table \ref{tabel:parameterestimates} displays the parameter estimates. The main explanatory variables are significantly different from zero
```{r Finalmodel}
#Final model after removing Log.HouseAge
model.poisson = glm(data = data, Number_of_Family ~ Log.Income + Log.Expenditure + 
                       Gender + Type + Bedrooms ,
                     family = poisson(link = "log"))
```

```{r parameterestimates, warning=FALSE, message=FALSE}
conf.int <- confint(model.poisson) %>% 
  data.frame() %>% rename("Lower CI"=1, "Upper CI"=2)
sum.coef <- summary(model.poisson)$coefficients

cbind(sum.coef, conf.int) %>% select(-3) %>% relocate(3, .after = 5) %>% 
  add_rownames(var = "parameter") %>% 
  kable(caption = "\\label{tabel:parameterestimates} parameter estimates of the Poisson regression model", 
        col.names = c("Parameter","Estimate", "Std. Error", "Lower CI","Upper CI",
                      "P.value"),
         digits = 3)
```

The rate ratio are obtained by exponentiating the coefficients(Table \ref{tabel:rateratio}). Figure \ref{fig:rateratiofig} exhibits the rate ration for the different explantory variables
```{r rateratio, warning=FALSE, message=FALSE}
cbind(exp(coef(model.poisson)), exp(confint(model.poisson))) %>% data.frame() %>% 
  rename("Estimate"=1, "Lower CI"=2, "Upper CI"=3) %>% 
  kable(caption = "\\label{tabel:rateratio} Rate ratios 95 percent confidence interval", digits = 2)
```

```{r rateratiofig, fig.cap="\\label{fig:rateratiofig} 95 percent rate ratios",warning=FALSE, message=FALSE}
plot_model(model.poisson, show.values = TRUE,
           title = "Rate ratio", show.p = FALSE, axis.lim = c(0.8,2.1)) +
  theme_light() + geom_hline(yintercept = 1, color = "deeppink") + 
  ylim(c(0.8, 2)) + 
  scale_y_continuous(breaks = seq(0.8,2.1,0.1))

```
Figure \ref{fig:variableseffect} shows the relationship between each of the variables and the outcome variable


```{r, variableseffect,  warning=FALSE, message=FALSE, fig.cap="\\label{fig:variableseffect} The relationship between explanatory variables and the number of family members"}
data <- data %>% mutate(pred = predict(model.poisson, type = "response"))



#Plots

models <- plot_model(model.poisson, type = "pred")

Log.Income <- models$Log.Income + 
  geom_smooth(color = "deeppink", se = F) +
  theme_classic() + theme(plot.title = element_blank())


Log.Expenditure <- models$Log.Expenditure + 
  geom_smooth(color = "deeppink", se = F) +
  theme_classic() + theme(plot.title = element_blank())

Gender <- models$Gender + 
  geom_point(color = "deeppink") +
  theme_classic() + theme(plot.title = element_blank())

Type <- models$Type + 
  geom_point(color = "deeppink") +
  theme_classic() + theme(plot.title = element_blank())

Bedrooms <- models$Bedrooms + 
  geom_smooth(color = "deeppink", se = F) +
  theme_classic() + theme(plot.title = element_blank())

grid.arrange(Log.Income, Log.Expenditure, Type, Gender, Bedrooms)
```

Figure \ref{fig:predictions} illustrates the predictions of the model. The difference between real values and predictions can be seen in Figure \ref{fig:comparison}

```{r predictions, fig.cap="\\label{fig:predictions} Histogram of predictions of the number of family members"}

predictions = data %>% 
  mutate(pred = round(predict(model.poisson, type = "response"))) %>% count(pred)

predictions <- rbind(predictions, data.frame("pred" = c(1, 14, 15), n = rep(0,3))) %>% 
  arrange(pred)


predictions %>% mutate(pct = n / sum(n),
       pctlabel = paste0(round(pct*100,1), "%")) %>% 
  ggplot(aes(x = as.factor(pred), y = n)) + 
  geom_bar(stat = "identity", 
           fill = "steelblue", 
           color = "black")  +
  geom_text(aes(label = pctlabel), 
            vjust = -0.25) + 
  labs(x = "Family size", 
       y = "Frequency", 
       title  = "Prediction histogram of the number of familiy members") + 
  theme_classic() 


```

```{r comparison, fig.cap="\\label{fig:comparison} Comparison between real data and predictions"}

right_join(predictions[,c(1,2)], plotdata[,c(1,2)], by = c("pred" = "Number_of_Family")) %>% 
  gather(number, count, -pred) %>% rename("Family.size" = 1, "Group" = 2) %>% 
  mutate(Group = replace(Group, Group == "n.y", "Real count"),
         Group = replace(Group, Group == "n.x", "Prediction")) %>% 
    ggplot(aes(x = as.factor(Family.size), y = count, fill = Group)) +
  geom_col(position = position_dodge()) + 
  labs(x = "Family size")+
  scale_fill_manual(
    values = c("Real count" = "indianred3", "Prediction" = "steelblue"))+
  theme_classic()


```
